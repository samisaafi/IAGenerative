from openai import OpenAI

print("üîç Test de connexion √† LM Studio...\n")

try:
    client = OpenAI(
        base_url="http://localhost:1234/v1",
        api_key="not-needed"
    )
    
    response = client.chat.completions.create(
        model="local-model",
        messages=[{"role": "user", "content": "Dis bonjour en fran√ßais"}],
        temperature=0.7
    )
    
    print("‚úÖ Connexion r√©ussie !")
    print(f"ü§ñ R√©ponse du mod√®le : {response.choices[0].message.content}")
    
except Exception as e:
    print(f"‚ùå Erreur : {e}")
    print("\n‚ö†Ô∏è  V√©rifiez que :")
    print("   1. LM Studio est ouvert")
    print("   2. Un mod√®le est charg√©")
    print("   3. Le serveur est d√©marr√©")